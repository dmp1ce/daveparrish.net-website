<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
    <head>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
        <title>Dave Parrish - Managing ZFS Snapshots: The Problem with Docker ZFS Datasets</title>

        <!-- Stylesheets. -->
        <link rel="stylesheet" type="text/css" href="../css/default.css" />
        <link rel="stylesheet" type="text/css" href="../css/syntax.css" />

        <!-- Metadata. -->
        <meta name="keywords" content="daveparrish,drupal,haskell,liberty,bitcoin,linux,blog,hakyll" />
        <meta name="description" content="Dave Parrish - Hakyll blog" />
    </head>
    <body>
        <div id="main">
            <div id="header">
                <a href="../">
                    <img src="../images/lambda.png" alt="lambda" />
                    Dave Parrish's Blog
                </a>
            </div>
            <!-- Sidebar. -->
            <div id="sidebar">
                <a href="../index.html">Home</a>
                <a href="../about.html">About</a>
                <a href="../projects.html">Projects</a>
                <a href="../contact.html">Contact</a>
                <a href="../archive.html">Archive</a>

            </div>

            <div id="content">
		<h1>Managing ZFS Snapshots: The Problem with Docker ZFS Datasets</h1>
                <div class="info">Posted on November 10, 2020</div>

<hr />
<p>On several occasions, I wanted to automatically create ZFS snapshots but I was faced with ignoring many datasets (created by Docker) which I don’t care about. Here is how to create automatic ZFS snapshots but ignore Docker snapshots.</p>
<ul>
<li><a href="#zfs">ZFS</a></li>
<li><a href="#docker-on-zfs">Docker on ZFS</a></li>
<li><a href="#auto-snapshots-with-docker-datasets">Auto snapshots with Docker datasets</a></li>
<li><a href="#migrating-docker-zfs-datasets">Migrating Docker ZFS datasets</a></li>
<li><a href>Syncoid Replication</a></li>
<li><a href="#conclusion">Conclusion</a></li>
</ul>
<h1 id="zfs">ZFS</h1>
<p>ZFS is a useful file system for me because of it’s redundancy and near instant snapshots. See <a href="https://en.wikipedia.org/wiki/ZFS#Features">ZFS’ long feature list</a>. ZFS is a great file system, but it isn’t standard for many Linux distributions because of <a href="https://openzfs.github.io/openzfs-docs/Project%20and%20Community/FAQ.html#licensing">licensing issues</a>.</p>
<p>ZFS is readily available on Ubuntu and Arch Linux as explained in their online documentation. The <a href="https://wiki.ubuntu.com/ZFS">Ubuntu ZFS documentation</a> can be used to install ZFS on any up-to-date Ubuntu setup and <a href="https://ubuntu.com/blog/zfs-focus-on-ubuntu-20-04-lts-whats-new">the Ubuntu install process can be used to install ZFS as the root file system</a>. <a href="https://wiki.archlinux.org/index.php/ZFS">Arch Linux ZFS documentation is very helpful in learning how to use ZFS</a> and <a href="https://github.com/danboid/ALEZ">the ALEZ installer can be used to setup a root ZFS system</a>.</p>
<h1 id="docker-on-zfs">Docker on ZFS</h1>
<p>Docker uses a compatible layered file system to manage it’s images. The file system used can be modified in the Docker settings. By default, on root ZFS system Docker will use ZFS as the file system for images. Also, by default, the datasets are created in the root of the pool which docker was installed. This causes Docker to create many datasets which look something like this:</p>
<pre><code>$ zfs list -d 1 zroot | head
NAME                                                                          USED  AVAIL     REFER  MOUNTPOINT
zroot                                                                        42.4G   132G       96K  none
zroot/0004106facc034e1d2d75d4372f4b7f28e1aba770e715b48d0ed1dd9221f70c9        212K   132G      532M  legacy
zroot/006a51b4a6b323b10e9885cc8ef9023a725307e61f334e5dd373076d80497a52       44.6M   132G      388M  legacy
zroot/00d07f72b0c5e3fed2f69eeebbe6d82cdc9c188c046244ab3163dbdac592ae2b       6.89M   132G     6.88M  legacy
zroot/011c18866423f0a535294033c020f4e548a8e07432262f80e8e488fa02fe250a       11.4M   132G      503M  legacy
zroot/013f7639f37b7a1263f3e65bbfd4890f1103c3c9e27a8f42e69083f6b1cba545        140K   132G     25.4M  legacy
zroot/01e79194da4df11f6fe8bcbd1a94885041d5d9269b0c744fe39c4d76101f2d56        262M   132G      309M  legacy
zroot/021fef9b5d63f0ff4b5621d1498a4e666ae38dd31660265e21f1a2bb0ac414f7        152K   132G      200M  legacy
zroot/022c3a6e9a40f3f62e3d13189970603b8b2ba6bb013817abd5db67c335e97e4c        116K   132G      162M  legacy</code></pre>
<h1 id="auto-snapshots-with-docker-datasets">Auto snapshots with Docker datasets</h1>
<p>zfs-auto-snapshot is a useful package, available on both <a href="https://aur.archlinux.org/packages/zfs-auto-snapshot/">Arch Linux</a> and <a href="http://manpages.ubuntu.com/manpages/focal/man8/zfs-auto-snapshot.8.html">Ubuntu</a>, for making snapshots automatically. This is great for accidental deletes or if wanting to get an earlier version of a file. Snapshots will take up more space over time, because deleted data will need to be kept around, but automatic snapshots can be turned off with the <code>com.sun:auto-snapshot=false</code> property set.</p>
<p>The problem comes in when automatic snapshots are combined with the many Docker datasets created. By default, if Docker has been used and zfs-auto-snapshot is running then <em>several</em> snapshots will be create for each and every Docker dataset. With so many snapshots, ZFS runs a little slower when listing snapshots for example. Also, there is no reason for the snapshots to exist because Docker datasets never change!</p>
<p>So, how can the auto snapshots be turned of for Docker datasets? The easiest thing to do would be to set <code>com.sun:auto-snapshot=false</code> on the parent dataset in ZFS. This will work, but usually, the parent dataset is a dataset which is wanted to be automatically snapshot because it has other data besides the Docker datasets. What needs to be done is to move the Docker datasets into their own dataset parent, where auto snapshots can be safely turned off without effecting snapshots for other data.</p>
<h2 id="zfs-auto-snapshot-aside">zfs-auto-snapshot aside</h2>
<p>It is also helpful to know <a href="https://unix.stackexchange.com/questions/398540/how-to-override-systemd-unit-file-settings">zfs-auto-snapshot systemd service files can be overriden</a> to <a href="http://manpages.ubuntu.com/manpages/focal/man8/zfs-auto-snapshot.8.html">exclude snapshots by default</a> using <code>--default-exclude</code>. I couldn’t figure out a way to use this to exclude the Docker datasets and include the parent dataset though. If <code>--default-exclude</code> is used, any dataset with the property <code>com.sun:auto-snapshot=true</code> will automatically be snapshot and none will be snapshot by default.</p>
<h1 id="migrating-docker-zfs-datasets">Migrating Docker ZFS datasets</h1>
<p>To move the Docker ZFS datasets, I followed the following steps:</p>
<ul>
<li><a href="#create-a-new-parent-dataset">Create a new parent dataset</a></li>
<li><a href="#set-new-dataset-location-for-docker">Set new dataset location for Docker</a></li>
<li><a href="#turn-off-docker">Turn off Docker</a></li>
<li><a href="#use-a-script-to-move-over-all-docker-datasets">Use a script to move over all Docker datasets</a></li>
<li><a href="#turn-on-docker">Turn on Docker</a></li>
</ul>
<h2 id="create-a-new-parent-dataset">Create a new parent dataset</h2>
<p>Create a new dataset where the Docker datasets can live. Something like command <code>sudo zfs create rpool/docker</code> should do it. Also, turn off automatic snapshots for that dataset with a command like <code>sudo zfs set com.sun:auto-snapshot=false rpool/docker</code>.</p>
<h2 id="turn-off-docker">Turn off Docker</h2>
<p>Turn off Docker service before changing Docker settings. The command <code>sudo systemctl stop docker</code> will turn of Docker service and all running Docker services.</p>
<h2 id="set-new-dataset-location-for-docker">Set new dataset location for Docker</h2>
<p>While Docker is off, the <code>/etc/docker/daemon.json</code> can be create/edited to contain the setting <code>&quot;storage-opts&quot;: [&quot;zfs.fsname=zroot/docker&quot;]</code>.</p>
<p>For example: <code>$ cat /etc/docker/dameon.json</code></p>
<pre><code>{
    &quot;storage-opts&quot;: [
        &quot;zfs.fsname=rpool/docker&quot;
    ]
}
</code></pre>
<h2 id="use-a-script-to-move-over-all-docker-datasets">Use a script to move over all Docker datasets</h2>
<p>Unfortunately, I do not know of built in way to move many child datasets. I had to use a bash script to move all the child datasets which in my case was only Docker datasets. For your case you might need to make a different script to target only the Docker datasets. Using a command like <code>./move_zfs_child_datasets.bash zpool/ROOT/default zpool/docker</code> should move all the datasets.</p>
<p>Here is the script I used to move the datasets:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb3-1" title="1"><span class="co">#!/bin/bash</span></a>
<a class="sourceLine" id="cb3-2" title="2"></a>
<a class="sourceLine" id="cb3-3" title="3"><span class="co"># Move all ZFS child datasets to a new parent dataset</span></a>
<a class="sourceLine" id="cb3-4" title="4"></a>
<a class="sourceLine" id="cb3-5" title="5"><span class="kw">if</span><span class="bu"> [</span> <span class="ot">!</span> <span class="va">$#</span> <span class="ot">-eq</span> 2<span class="bu"> ]</span>; <span class="kw">then</span></a>
<a class="sourceLine" id="cb3-6" title="6">    <span class="bu">echo</span> <span class="st">&quot;Please supply a source and destination ZFS dataset as the first and second parameter&quot;</span></a>
<a class="sourceLine" id="cb3-7" title="7">    <span class="bu">echo</span> <span class="st">&quot;Example: ./move_zfs_child_datasets.bash zpool/ROOT/default zpool/docker&quot;</span></a>
<a class="sourceLine" id="cb3-8" title="8">    <span class="bu">exit</span><span class="kw">;</span></a>
<a class="sourceLine" id="cb3-9" title="9"><span class="kw">fi</span></a>
<a class="sourceLine" id="cb3-10" title="10"></a>
<a class="sourceLine" id="cb3-11" title="11"><span class="va">currentDatasetPath=$1</span></a>
<a class="sourceLine" id="cb3-12" title="12"><span class="va">newDatasetPath=$2</span></a>
<a class="sourceLine" id="cb3-13" title="13"></a>
<a class="sourceLine" id="cb3-14" title="14"><span class="va">currentDatasets=$(</span><span class="ex">zfs</span> list -H -t filesystem -d 1 -o name <span class="st">&quot;</span><span class="va">$currentDatasetPath</span><span class="st">&quot;</span> <span class="kw">|</span> <span class="fu">tail</span> +2<span class="va">)</span></a>
<a class="sourceLine" id="cb3-15" title="15"></a>
<a class="sourceLine" id="cb3-16" title="16"><span class="kw">for</span> <span class="ex">dataset</span> in <span class="va">$currentDatasets</span> <span class="kw">;</span> <span class="kw">do</span></a>
<a class="sourceLine" id="cb3-17" title="17">    <span class="va">newDataset=</span><span class="st">&quot;</span><span class="va">$newDatasetPath</span><span class="st">/</span><span class="va">${dataset##</span>*/<span class="va">}</span><span class="st">&quot;</span></a>
<a class="sourceLine" id="cb3-18" title="18">    <span class="bu">echo</span> <span class="st">&quot;Move </span><span class="va">$dataset</span><span class="st"> to </span><span class="va">$newDataset</span><span class="st">&quot;</span></a>
<a class="sourceLine" id="cb3-19" title="19">    <span class="fu">sudo</span> zfs rename <span class="st">&quot;</span><span class="va">$dataset</span><span class="st">&quot;</span> <span class="st">&quot;</span><span class="va">$newDataset</span><span class="st">&quot;</span></a>
<a class="sourceLine" id="cb3-20" title="20"><span class="kw">done</span></a></code></pre></div>
Or the Gist version:
<script src="https://gist.github.com/dmp1ce/5f51f798eee3806654f171e2b0272590.js"></script>
<h2 id="turn-on-docker">Turn on Docker</h2>
<p>After moving all the datasets, it should be safe to turn Docker back on. All Docker services should resume as normal. Start Docker with the command <code>sudo systemctl start docker</code>.</p>
<h1 id="syncoid-replication">Syncoid replication</h1>
<p>Another reason why I didn’t want all the Docker datasets and snapshots is because syncoid commands took a long time. Even when nothing changed, I found it took 10 minutes just to traverse all of the snapshots! With Docker datasets on their own parent dataset, it is straightforward to exclude Docker datasets during replication.</p>
<p>I use a command like <code>syncoid --exclude=&quot;zroot\/docker&quot; --exclude=&quot;zroot\/docker\/[\w]+(-init)?&quot; --exclude=&quot;zroot/swap&quot; -r zroot myserver:rpool/backups/mylaptop/zroot</code> to replicate almost all of the ZFS data on another computer.</p>
<h2 id="why-syncoid">Why Syncoid</h2>
<p>I wanted to take advantage of ZFS for quick backups. I have some big datasets and I felt like Syncoid which takes advantage of <code>zfs send</code> made the most sense.</p>
<p>I would have liked to figure out how to encrypt the destination of the replication, but other than that, the replication process works very well, after the many snapshots from Docker datasets are excluded.</p>
<h2 id="installing-syncoid">Installing Syncoid</h2>
<p>On both Ubuntu and Arch Linux I needed some extra packages for Syncoid to work optimally. <a href="https://aur.archlinux.org/packages/mbuffer/">mbuffer</a> and <a href="https://www.archlinux.org/packages/extra/x86_64/lzop/">lzop</a> also needed to be installed along with <a href="https://aur.archlinux.org/packages/sanoid/">sanoid</a> from the AUR for Arch Linux. For Ubuntu <a href="https://packages.ubuntu.com/focal/sanoid">sanoid</a>, <a href="https://www.archlinux.org/packages/extra/x86_64/lzop/">lzop</a> and <a href="https://packages.ubuntu.com/focal/mbuffer">mbuffer</a> should also be installed for Syncoid.</p>
<p>I don’t think sanoid needs to be installed if you are not running the syncoid command on that system, although mbuffer and lzop might still be required on a remote ZFS server.</p>
<h1 id="conclusion">Conclusion</h1>
<p>After going through all this effort to avoid syncing unnecessary datasets and snapshots, I’m still not sure it is worth it. Maybe my time would have been better spent setting up a Borg Backup configuration and not worry about these ZFS issues. On the other hand, my replications of datasets is now very fast, easy to maintain and kept at a minimum size.</p>
<p>Hopefully this will be useful to more than just myself. I know I learned more about how ZFS handles datasets and snapshots. Please let me know if you know a better way to backup/replicate ZFS datasets while ignoring unnecessary datasets like Docker creates.</p>

<em>Modified: November 10, 2020 - 09:40:48 PM</em>

            </div>

            <div id="footer">
                Site proudly generated by <a href="http://github.com/jaspervdj/hakyll">hakyll</a>.<br />
                Generated HTML hosted on <a href="https://vultr.com">Vultr</a> and maintained with <a href="https://www.ansible.com">Ansible</a>.<br />
            </div>
        </div>
    </body>
</html>
